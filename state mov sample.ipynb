{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 1 fields in line 198915, saw 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-69206583fdb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;34m\"twitter_clean.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skip_footer not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   1759\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0malldata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rows_to_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exclude_implicit_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_rows_to_cols\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m   2164\u001b[0m             msg = ('Expected %d fields in line %d, saw %d' %\n\u001b[1;32m   2165\u001b[0m                    (col_len, row_num + 1, zip_len))\n\u001b[0;32m-> 2166\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 1 fields in line 198915, saw 13"
     ]
    }
   ],
   "source": [
    "sample  = pd.read_csv(  \"twitter_clean.csv\", \"rb\" )\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "userId                0\n",
       "text                  0\n",
       "longitude          4514\n",
       "latitude           4514\n",
       "inReplyTo         17246\n",
       "placeLatitude         0\n",
       "placeLongitude        0\n",
       "followersCount        0\n",
       "friendsCount          0\n",
       "statusesCount         0\n",
       "userLocation        415\n",
       "year                  0\n",
       "month                 0\n",
       "day                   0\n",
       "week_number           0\n",
       "hour                  0\n",
       "city                 41\n",
       "state                 3\n",
       "country               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22611, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few cities and states is not found, so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "userId                0\n",
       "text                  0\n",
       "longitude          4514\n",
       "latitude           4514\n",
       "inReplyTo         17243\n",
       "placeLatitude         0\n",
       "placeLongitude        0\n",
       "followersCount        0\n",
       "friendsCount          0\n",
       "statusesCount         0\n",
       "userLocation        415\n",
       "year                  0\n",
       "month                 0\n",
       "day                   0\n",
       "week_number           0\n",
       "hour                  0\n",
       "city                 41\n",
       "state                 0\n",
       "country               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_all=sample.dropna(subset=['country','state','year','month','week_number','day','hour'])\n",
    "user_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18898, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=user_all.loc[user_all['country']=='ch']\n",
    "user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning unusual trajectories\n",
    "\n",
    "Revocer time for calculating valid user in reasonable moving speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>placeLatitude</th>\n",
       "      <th>placeLongitude</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>...</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_number</th>\n",
       "      <th>hour</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>10231423626</td>\n",
       "      <td>6257282.0</td>\n",
       "      <td>The new apartment is nice, but there is no Wif...</td>\n",
       "      <td>7.58531</td>\n",
       "      <td>47.5455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5367</td>\n",
       "      <td>7.57849</td>\n",
       "      <td>14249</td>\n",
       "      <td>9260.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Potsdam, Germany</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Binningen</td>\n",
       "      <td>Basel-Landschaft</td>\n",
       "      <td>ch</td>\n",
       "      <td>2010-03-09 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>10292646240</td>\n",
       "      <td>15602037.0</td>\n",
       "      <td>Is that wet yet solid stuff on my screen suppo...</td>\n",
       "      <td>8.52725</td>\n",
       "      <td>47.3876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.3791</td>\n",
       "      <td>8.50021</td>\n",
       "      <td>177</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Zürich, Switzerland</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Zürich</td>\n",
       "      <td>Zürich</td>\n",
       "      <td>ch</td>\n",
       "      <td>2010-03-10 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>10309829732</td>\n",
       "      <td>625553.0</td>\n",
       "      <td>I'm at DCTI - David Dufour in Geneva http://go...</td>\n",
       "      <td>6.13183</td>\n",
       "      <td>46.2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.1996</td>\n",
       "      <td>6.13011</td>\n",
       "      <td>471</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Genève</td>\n",
       "      <td>Genève</td>\n",
       "      <td>ch</td>\n",
       "      <td>2010-03-11 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>10310391132</td>\n",
       "      <td>17341045.0</td>\n",
       "      <td>God morgon! :-)</td>\n",
       "      <td>7.44235</td>\n",
       "      <td>46.8957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.9214</td>\n",
       "      <td>7.38855</td>\n",
       "      <td>586</td>\n",
       "      <td>508.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Bern, Switzerland</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Köniz</td>\n",
       "      <td>Bern - Berne</td>\n",
       "      <td>ch</td>\n",
       "      <td>2010-03-11 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>10311568050</td>\n",
       "      <td>634553.0</td>\n",
       "      <td>At this very minute, the sun is pink.</td>\n",
       "      <td>6.19900</td>\n",
       "      <td>46.2043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.1938</td>\n",
       "      <td>6.15415</td>\n",
       "      <td>2230</td>\n",
       "      <td>387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Genève</td>\n",
       "      <td>Genève</td>\n",
       "      <td>ch</td>\n",
       "      <td>2010-03-11 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id      userId  \\\n",
       "551  10231423626   6257282.0   \n",
       "609  10292646240  15602037.0   \n",
       "611  10309829732    625553.0   \n",
       "612  10310391132  17341045.0   \n",
       "618  10311568050    634553.0   \n",
       "\n",
       "                                                  text  longitude  latitude  \\\n",
       "551  The new apartment is nice, but there is no Wif...    7.58531   47.5455   \n",
       "609  Is that wet yet solid stuff on my screen suppo...    8.52725   47.3876   \n",
       "611  I'm at DCTI - David Dufour in Geneva http://go...    6.13183   46.2006   \n",
       "612                                    God morgon! :-)    7.44235   46.8957   \n",
       "618              At this very minute, the sun is pink.    6.19900   46.2043   \n",
       "\n",
       "     inReplyTo  placeLatitude  placeLongitude followersCount  friendsCount  \\\n",
       "551        NaN        47.5367         7.57849          14249        9260.0   \n",
       "609        NaN        47.3791         8.50021            177         136.0   \n",
       "611        NaN        46.1996         6.13011            471          82.0   \n",
       "612        NaN        46.9214         7.38855            586         508.0   \n",
       "618        NaN        46.1938         6.15415           2230         387.0   \n",
       "\n",
       "            ...                 userLocation    year  month   day  \\\n",
       "551         ...             Potsdam, Germany  2010.0    3.0   9.0   \n",
       "609         ...          Zürich, Switzerland  2010.0    3.0  10.0   \n",
       "611         ...          Geneva, Switzerland  2010.0    3.0  11.0   \n",
       "612         ...            Bern, Switzerland  2010.0    3.0  11.0   \n",
       "618         ...          Geneva, Switzerland  2010.0    3.0  11.0   \n",
       "\n",
       "     week_number  hour       city             state country  \\\n",
       "551         10.0  18.0  Binningen  Basel-Landschaft      ch   \n",
       "609         10.0  22.0     Zürich            Zürich      ch   \n",
       "611         10.0   5.0     Genève            Genève      ch   \n",
       "612         10.0   6.0      Köniz      Bern - Berne      ch   \n",
       "618         10.0   7.0     Genève            Genève      ch   \n",
       "\n",
       "                   time  \n",
       "551 2010-03-09 18:00:00  \n",
       "609 2010-03-10 22:00:00  \n",
       "611 2010-03-11 05:00:00  \n",
       "612 2010-03-11 06:00:00  \n",
       "618 2010-03-11 07:00:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "t_count=user[['year','month','day','hour']]\n",
    "temp=pd.to_datetime(t_count)\n",
    "temp.head()\n",
    "user['time']=temp\n",
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# velticity calculation, miles per hour\n",
    "from geopy.distance import vincenty \n",
    "\n",
    "def speed(loc1, loc2, t1, t2):\n",
    "    d = vincenty(loc1,loc2).miles\n",
    "    dt = t2-t1\n",
    "    dh = dt.seconds/3600.0 #to_hours\n",
    "    if dh :\n",
    "        return d/dh \n",
    "    else: #within one hour, assume it travels within half an hour\n",
    "        return d/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ref: Exploring Multi-Scale Spatiotemporal Twitter User Mobility Patterns with a Visual-Analytics Approach\n",
    "#Space-Time Twitter User Trajectories\n",
    "#To remove non-human users based on unusual relocating speed: e.g. speed (loc_i − loc_i−1) > 240 m/s\n",
    "\n",
    "#Travelling in Switzerland mainly takes train(despite some ones take flight)\n",
    "#Data are in time-order, so the location is continuously changed\n",
    "#Since we clean the data before, time is accurate to hour, so we set a loose thedshold like 200 mils/h \n",
    "\n",
    "\n",
    "#remove non-human user\n",
    "def human_user(c_tuple, speed_thed=200):\n",
    "    lon,lan,t = tuple(zip(*c_tuple))\n",
    "    point = list(zip(lan,lon))\n",
    "    normal=[True]*(len(c_tuple))\n",
    "    \n",
    "    if len(c_tuple) == 1:\n",
    "        normal[0] = False # remove only one tweet\n",
    "    if len(c_tuple) == 2 :\n",
    "        v = speed(point[0],point[1],t[0],t[1])\n",
    "        if v > speed_thed:\n",
    "            normal = [False]*(len(c_tuple))\n",
    "    else:\n",
    "        loc1 = point[0:-2]\n",
    "        loc2 = point[1:-1]\n",
    "        loc3 = point[2::]\n",
    "        #Using geopy's vincenty to find distances in pandas data frame\n",
    "        for i in range(len(loc1)):\n",
    "            v1_2=speed(loc2[i],loc1[i],t[i],t[i+1])\n",
    "            v2_3=speed(loc2[i],loc3[i],t[i+1],t[i+2])\n",
    "            v1_3=speed(loc1[i],loc3[i],t[i],t[i+2])\n",
    "        \n",
    "            # Check if loc1 is a normal location with reasonable speed\n",
    "            # If there is something wrong with loc1->loc2, we check loc2->loc3 & loc1->loc3 to ensure if loc2/3 is wrong\n",
    "        \n",
    "            if v1_2 > speed_thed: # loc1->loc2 innormal\n",
    "                if v2_3 > speed_thed: # loc2->loc1/3 innormal -> loc2 innormal\n",
    "                    normal[i+1]=False \n",
    "                    if v1_3 > speed_thed: # loc1->loc2/3 innormal -> loc1 innormal\n",
    "                        normal[i]=False \n",
    "                        if i == len(loc1)-1: # last index with all wrong\n",
    "                            normal[i+2]=False\n",
    "                else: # loc1->loc2 innormal, loc2->loc1/3 normal -> loc2 normal, loc1 innormal\n",
    "                    normal[i]=False\n",
    "            else: # loc1->loc2 normal\n",
    "                if v2_3 > speed_thed:\n",
    "                    if v1_3 > speed_thed: # loc3->loc1/2 innormal -> loc3 innormal\n",
    "                        normal[i+2]=False\n",
    "                    else:\n",
    "                        if (i == len(loc1)-1): # last index, just loc2->loc3 innormal -> loc2 innormal\n",
    "                            normal[i+1]=False\n",
    "        \n",
    "    return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#twitter_user=twitter_data.groupby(twitter_data['userId'])\n",
    "#.order(ascending=True)\n",
    "user_trace=['userId','year','month','week_number','day']\n",
    "user['temp'] = tuple(zip(user['placeLatitude'],user['placeLongitude'],user['time']))\n",
    "normal = user.groupby(by=user_trace)['temp'].transform(lambda x: human_user(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13256, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_user = user[normal].reset_index(drop=True)\n",
    "normal_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store trace\n",
    "\n",
    "Next,we hope to define daily trace of every user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since tweets are in time order, we can just store daily trace by apprending locations(canton)\n",
    "\n",
    "def daily_trace(r_location):\n",
    "    start=r_location.values[0:-1]\n",
    "    end=r_location.values[1::]\n",
    "    index=(start!=end)\n",
    "    trace=np.nan\n",
    "    \n",
    "    if index.any(): # Remove inner-canton trace \n",
    "        trace='->'.join(start[index])\n",
    "        trace='->'.join([trace,end[index][-1]])\n",
    "        \n",
    "    return trace    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3925,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dtrace = normal_user.groupby(by=user_trace)['state'].apply(lambda x: daily_trace(x))\n",
    "trace_copy = user_dtrace.copy()\n",
    "trace_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dtrace.dropna(inplace=True)\n",
    "user_dtrace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open ( \"state_mov.p\", \"wb\" ) as output:\n",
    "    pickle.dump(user_dtrace, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "d={'a':[1,2,3],'b':[pd.NaT,pd.to_datetime('20140201'),pd.NaT],'c':['w','g','x']}\n",
    "test=pd.DataFrame(data=d)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[True,False,False]})\n",
    "df.astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### test\n",
    "\n",
    "n_split=100\n",
    "n_user=np.array_split(user, n_split)\n",
    "n_judge=np.array_split(normal, n_split)\n",
    "\n",
    "\n",
    "def split_judge(user,judge,r1,r2):\n",
    "    frames=[]\n",
    "    for i in range(r1,r2):\n",
    "        df=n_user[i][n_judge[i]]\n",
    "        frames.append(df)\n",
    "    return frames\n",
    "\n",
    "clean_data[0] = split_judge(n_user[0:10],n_judge[0:10],0,10)\n",
    "#clean_data[1] = split_judge(n_user[11:20],n_judge[11:20],11,20)\n",
    "clean_data[2] = split_judge(n_user[21:30],n_judge[21:30],21,30)\n",
    "clean_data[3] = split_judge(n_user[31:40],n_judge[31:40],31,40)\n",
    "clean_data[4] = split_judge(n_user[41:50],n_judge[41:50],41,50)\n",
    "clean_data[5] = split_judge(n_user[51:60],n_judge[51:60],51,60)\n",
    "clean_data[6] = split_judge(n_user[61:70],n_judge[61:70],61,70)\n",
    "clean_data[7] = split_judge(n_user[71:80],n_judge[71:80],71,80)\n",
    "clean_data[8] = split_judge(n_user[81:90],n_judge[81:90],81,90)\n",
    "clean_data[9] = split_judge(n_user[91:100],n_judge[91:100],91,100)\n",
    "\n",
    "for n in range(10):\n",
    "    frames=[]\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        df=n_user[n*10+i][n_judge[n*10+i]]\n",
    "        frames.append(df)\n",
    "    #normal_user = pd.concat([normal_user,frames])\n",
    "    clean_data[n] = pd.concat(frames)\n",
    "    #clean_data.append(frames)\n",
    "\n",
    "normal_user=clean_data[0]\n",
    "for n in range(1,10):\n",
    "    normal_user = pd.concat([normal_user,clean_data[n]])\n",
    "#normal_user = pd.concat(frames)\n",
    "normal_user.shape\n",
    "\n",
    "#n_user[0][n_judge[0]]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
